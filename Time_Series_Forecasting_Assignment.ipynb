{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmH5EfpswrkN"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from lightgbm import LGBMRegressor\n",
        "import xgboost as xgb\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Reload dataset\n",
        "df = pd.read_csv(\"/content/hour.csv\")\n",
        "\n",
        "print(\"First few rows of data:\")\n",
        "display(df.head())\n",
        "# Convert 'dteday' string to datetime\n",
        "df['dteday'] = pd.to_datetime(df['dteday'])\n",
        "\n",
        "# Plot 1: Distribution of target variable 'cnt'\n",
        "print(\"\\n\")\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df['cnt'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Hourly Bike Rentals (cnt)')\n",
        "plt.xlabel('Rental Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Average rentals by hour\n",
        "print(\"\\n\")\n",
        "hr_avg = df.groupby('hr')['cnt'].mean()\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.lineplot(x=hr_avg.index, y=hr_avg.values, marker='o')\n",
        "plt.title('Average Hourly Bike Rentals')\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Average Rentals')\n",
        "plt.xticks(range(0, 24))\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot 3: Trend of rentals over time\n",
        "print(\"\\n\")\n",
        "plt.figure(figsize=(12, 5))\n",
        "df_daily = df.groupby('dteday')['cnt'].sum().reset_index()\n",
        "sns.lineplot(data=df_daily, x='dteday', y='cnt', color='coral')\n",
        "plt.title('Daily Bike Rental Trends')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Rentals')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nSummary Statistics:\")\n",
        "display(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s33DtzggxeqQ"
      },
      "outputs": [],
      "source": [
        "# missing values\n",
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot correlation matrix\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "corr = df.corr()\n",
        "corr_cnt = corr['cnt'].sort_values(ascending=False)\n",
        "\n",
        "#plot correlation using bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=corr_cnt.values,y=corr_cnt.index,hue=corr_cnt.index,palette='viridis',dodge=False,legend=False)\n",
        "plt.title('Correlation of Features with Target Variable (cnt)')\n",
        "plt.xlabel('Correlation Coefficient')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nCorrelation with respect to total bike rental:\\n\",corr_cnt)\n",
        "\n",
        "best_features = corr_cnt[['temp','hr']]\n",
        "print(\"\\nBest features with respect to total bike rental:\\n\",best_features)"
      ],
      "metadata": {
        "id": "u59v2szu7ZXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate IQR\n",
        "Q1 = df['cnt'].quantile(0.25)\n",
        "Q3 = df['cnt'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Calculate bounds\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "df = df[(df['cnt'] >= lower_bound) & (df['cnt'] <= upper_bound)].copy()\n",
        "\n",
        "print(f\"Q1: {Q1}\")\n",
        "print(f\"Q3: {Q3}\")\n",
        "print(f\"IQR: {IQR}\")\n",
        "print(f\"Lower Bound (IQR): {lower_bound}\")\n",
        "print(f\"Upper Bound (IQR): {upper_bound}\")\n",
        "\n",
        "# Visualize with box plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(y=df['cnt'])\n",
        "plt.title('Box Plot of Hourly Bike Rentals (cnt)')\n",
        "plt.ylabel('Rental Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r4xmHSiVEjH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MU4yZjr50zv"
      },
      "outputs": [],
      "source": [
        "# seperating weekdays, weekends etc for time trends\n",
        "df['hour'] = df['hr']\n",
        "df['day'] = pd.to_datetime(df['dteday']).dt.day\n",
        "df['weekday'] = pd.to_datetime(df['dteday']).dt.weekday\n",
        "df['month'] = pd.to_datetime(df['dteday']).dt.month\n",
        "df['year'] = pd.to_datetime(df['dteday']).dt.year\n",
        "\n",
        "#dropping unwanted columns\n",
        "df_model = df.drop(columns=['instant', 'dteday', 'casual','hr','mnth','yr','atemp'])\n",
        "\n",
        "df_model.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlation of all features with the target\n",
        "correlations = df_model.corr()['cnt'].drop('cnt')  # drop 'cnt' itself\n",
        "top_features = correlations.abs().sort_values(ascending=False).head(5).index.tolist()\n",
        "\n",
        "print(\"\\nTop Correlated Features with 'cnt':\")\n",
        "print(correlations[top_features])\n",
        "\n",
        "top_n = 5\n",
        "top_corr = df_model.corr()['cnt'].abs().sort_values(ascending=False).head(top_n + 1).index  # +1 to include 'cnt' itself\n",
        "top_corr_matrix = df_model[top_corr].corr()\n",
        "\n",
        "print(\"\\n\")\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(top_corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, linewidths=0.5)\n",
        "plt.title(f\"Heatmap of Top {top_n} Features Correlated with 'cnt'\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "r3kV95zOvKwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping registered feature\n",
        "df_model = df.drop(columns=['instant', 'dteday', 'casual','hr','mnth','yr','atemp','registered'])\n",
        "df_model.head()"
      ],
      "metadata": {
        "id": "TiYnCpCJ9Mzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize or standardize columns\n",
        "to_scale = ['temp', 'hum', 'windspeed']\n",
        "scaler = StandardScaler()\n",
        "df_model[to_scale] = scaler.fit_transform(df_model[to_scale])\n",
        "df_model.head()"
      ],
      "metadata": {
        "id": "0x0w6RFxCkXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R4ThX-4_bGN"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Features and target\n",
        "X = df_model.drop(['cnt','day'], axis=1)\n",
        "y = df_model['cnt']\n",
        "\n",
        "# Split data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False, random_state=42)\n",
        "\n",
        "# Second split: Validation (15%) and Test (15%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False, random_state=42)\n",
        "\n",
        "# Initialize models\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "xgbr = xgb.XGBRegressor(random_state=42)\n",
        "lgbm = LGBMRegressor(random_state=42, verbose=-1)\n",
        "\n",
        "# Train models\n",
        "rf.fit(X_train, y_train)\n",
        "xgbr.fit(X_train, y_train)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Evaluate function\n",
        "def evaluate_model(model, X, y, name=\"Model\"):\n",
        "    pred = model.predict(X)\n",
        "    mae = mean_absolute_error(y, pred)\n",
        "    mse = mean_squared_error(y, pred)\n",
        "    r2 = r2_score(y, pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(f\"{name} Evaluation:\")\n",
        "    print(\"MAE:\", mae)\n",
        "    print(\"MSE:\", mse)\n",
        "    print(\"RÂ²:\", r2)\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print()\n",
        "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
        "\n",
        "# Evaluation\n",
        "eval_models_table = pd.DataFrame([\n",
        "    evaluate_model(rf, X_test, y_test, \"Random Forest Regressor\"),\n",
        "    evaluate_model(xgbr, X_test, y_test, \"XGBoost Regressor\"),\n",
        "    evaluate_model(lgbm, X_test, y_test, \"LGBM Regressor\")\n",
        "])\n",
        "\n",
        "eval_models_table.index = ['Random Forest Regressor', 'XGBoost Regressor', 'LGBM Regressor']\n",
        "eval_models_table"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models with example hyperparameters\n",
        "rf_model_1 = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_model_2 = RandomForestRegressor(n_estimators=200, max_depth=20, random_state=42)\n",
        "\n",
        "xgbr_model_1 = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgbr_model_2 = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, random_state=42)\n",
        "\n",
        "lgbm_model_1 = LGBMRegressor(n_estimators=100, num_leaves=31, random_state=42, verbose = -1)\n",
        "lgbm_model_2 = LGBMRegressor(n_estimators=200, num_leaves=50, random_state=42, verbose = -1)\n",
        "\n",
        "# Train models on the training set\n",
        "rf_model_1.fit(X_train, y_train)\n",
        "rf_model_2.fit(X_train, y_train)\n",
        "xgbr_model_1.fit(X_train, y_train)\n",
        "xgbr_model_2.fit(X_train, y_train)\n",
        "lgbm_model_1.fit(X_train, y_train)\n",
        "lgbm_model_2.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Evaluate models on the validation set\n",
        "print(\"--- Evaluation on Validation Set ---\")\n",
        "rf1 = evaluate_model(rf_model_1, X_val, y_val, \"Random Forest Model 1\")\n",
        "rf2 = evaluate_model(rf_model_2, X_val, y_val, \"Random Forest Model 2\")\n",
        "xgbr1 = evaluate_model(xgbr_model_1, X_val, y_val, \"XGBoost Model 1\")\n",
        "xgbr2 = evaluate_model(xgbr_model_2, X_val, y_val, \"XGBoost Model 2\")\n",
        "lgbm1 = evaluate_model(lgbm_model_1, X_val, y_val, \"LGBM Model 1\")\n",
        "lgbm2 = evaluate_model(lgbm_model_2, X_val, y_val, \"LGBM Model 2\")\n",
        "\n",
        "# Based on the validation results, select the best model for each type\n",
        "# For demonstration, let's assume model 2 of each type performed better\n",
        "if rf2['R2'] > rf1['R2']:\n",
        "    best_rf_model = rf_model_2\n",
        "else:\n",
        "    best_rf_model = rf_model_1\n",
        "\n",
        "# Corrected logic for comparing XGBoost models\n",
        "if xgbr2['R2'] > xgbr1['R2']:\n",
        "    best_xgbr_model = xgbr_model_2\n",
        "else:\n",
        "    best_xgbr_model = xgbr_model_1\n",
        "\n",
        "if lgbm2['R2'] > lgbm1['R2']:\n",
        "    best_lgbm_model = lgbm_model_2\n",
        "else:\n",
        "    best_lgbm_model = lgbm_model_1\n",
        "# Finally, evaluate the selected best models on the test set\n",
        "print(\"\\n--- Final Evaluation on Test Set (Selected Best Models from Validation) ---\")\n",
        "eval_valid_table = pd.DataFrame([\n",
        "    evaluate_model(best_rf_model, X_test, y_test, \"Best Random Forest Model (Validated)\"),\n",
        "    evaluate_model(best_xgbr_model, X_test, y_test, \"Best XGBoost Model (Validated)\"),\n",
        "    evaluate_model(best_lgbm_model, X_test, y_test, \"Best LGBM Model (Validated)\")\n",
        "])\n",
        "eval_valid_table.index = ['Best Random Forest Model (Validated)', 'Best XGBoost Model (Validated)', 'Best LGBM Model (Validated)']\n",
        "eval_valid_table"
      ],
      "metadata": {
        "id": "DB4igJ_85KHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dictionary of model names and predictions\n",
        "models = {\n",
        "    \"XGBoost\": (xgbr, 'purple'),\n",
        "    \"Random Forest\": (rf, 'green'),\n",
        "    \"LGBM\": (lgbm, 'orange')\n",
        "}\n",
        "\n",
        "# Predict and store predictions\n",
        "predictions = {name: model.predict(X_test) for name, (model, _) in models.items()}\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "for i, (name, pred) in enumerate(predictions.items(), start=1):\n",
        "    color = models[name][1]\n",
        "    plt.subplot(len(models), 1, i)\n",
        "    plt.scatter(y_test, pred, alpha=0.5, color=color)\n",
        "    plt.plot([0, 1000], [0, 1000], 'r--')\n",
        "    plt.title(f'{name}: Actual vs Predicted')\n",
        "    plt.xlabel('Actual cnt')\n",
        "    plt.ylabel('Predicted cnt')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yd7kdlWyYNGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Expanded parameter grid\n",
        "param_dists = {\n",
        "    \"Random Forest\": {\n",
        "        'n_estimators': randint(200, 800),\n",
        "        'max_depth': [10, 20, 30, None],\n",
        "        'min_samples_split': randint(2, 15),\n",
        "        'min_samples_leaf': randint(1, 10),\n",
        "        'max_features': ['sqrt', 'log2', None]\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        'n_estimators': randint(200, 700),\n",
        "        'max_depth': randint(4, 12),\n",
        "        'learning_rate': uniform(0.01, 0.1),\n",
        "        'subsample': uniform(0.7, 0.3),\n",
        "        'colsample_bytree': uniform(0.7, 0.3),\n",
        "        'reg_alpha': uniform(0, 5),\n",
        "        'reg_lambda': uniform(0, 5)\n",
        "    },\n",
        "    \"LGBM\": {\n",
        "        'n_estimators': randint(200, 700),\n",
        "        'max_depth': [-1, 10, 20],\n",
        "        'learning_rate': uniform(0.01, 0.1),\n",
        "        'num_leaves': randint(31, 150),\n",
        "        'feature_fraction': uniform(0.7, 0.3),\n",
        "        'reg_alpha': uniform(0, 5),\n",
        "        'reg_lambda': uniform(0, 5)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0),\n",
        "    \"LGBM\": LGBMRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "n_iterations = 30  # More iterations for better tuning\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTuning {name} with RandomizedSearchCV ({n_iterations} iterations)...\")\n",
        "    random_search = RandomizedSearchCV(\n",
        "        model,\n",
        "        param_distributions=param_dists[name],\n",
        "        n_iter=n_iterations,\n",
        "        cv=5,\n",
        "        scoring='r2',\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbose=0\n",
        "    )\n",
        "    random_search.fit(X_train, y_train)\n",
        "    best_models[name] = random_search.best_estimator_\n",
        "    print(f\"Best Parameters for {name}:\", random_search.best_params_)\n",
        "\n",
        "# Evaluate models\n",
        "print(\"\\n--- Evaluation of Tuned Models (Randomized Search) ---\\n\")\n",
        "best_tuned = []\n",
        "for name, model in best_models.items():\n",
        "    best_tuned.append(pd.DataFrame([evaluate_model(model, X_test, y_test, f\"{name} (Tuned)\")]))\n",
        "\n",
        "best_tuned_df = pd.concat(best_tuned, ignore_index=True)\n",
        "best_tuned_df.index = ['Random Forest (Tuned) Evaluation', 'XGBoost (Tuned) Evaluation', 'LGBM (Tuned) Evaluation']\n",
        "best_tuned_df"
      ],
      "metadata": {
        "id": "jkjJNL38w4x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, X_test, y_test, label):\n",
        "    y_pred = model.predict(X_test)\n",
        "    return {\n",
        "        \"Model\": label,\n",
        "        \"R2\": r2_score(y_test, y_pred),\n",
        "        \"MSE\": mean_squared_error(y_test, y_pred),\n",
        "        \"MAE\": mean_absolute_error(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "# Evaluate Default Models\n",
        "default_results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    res = evaluate_model(model, X_test, y_test, f\"{name} (Default)\")\n",
        "    default_results.append(res)\n",
        "\n",
        "# Evaluate Tuned Models\n",
        "tuned_results = []\n",
        "for name, model in best_models.items():\n",
        "    res = evaluate_model(model, X_test, y_test, f\"{name} (Tuned)\")\n",
        "    tuned_results.append(res)\n",
        "\n",
        "# Combine Results\n",
        "all_results = pd.DataFrame(default_results + tuned_results)\n",
        "\n",
        "# Plot R2, MAE, MSE Comparisons\n",
        "metrics = ['R2', 'MAE', 'MSE']\n",
        "for metric in metrics:\n",
        "    fig = px.bar(\n",
        "        all_results, x=\"Model\", y=metric,\n",
        "        color=\"Model\", title=f\"{metric} Comparison: Default vs Tuned\",\n",
        "        text_auto='.3s'\n",
        "    )\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "poLOi9dsdDIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def plot_actual_vs_predicted(models_dict, X_test, y_test, title_suffix=\"\"):\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    for i, (name, model) in enumerate(models_dict.items()):\n",
        "        y_pred = model.predict(X_test)\n",
        "        plt.subplot(1, len(models_dict), i + 1)\n",
        "        sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)\n",
        "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "        plt.xlabel(\"Actual\")\n",
        "        plt.ylabel(\"Predicted\")\n",
        "        plt.title(f\"{name} {title_suffix}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usage\n",
        "plot_actual_vs_predicted(models, X_test, y_test, \"(Default)\")\n",
        "plot_actual_vs_predicted(best_models, X_test, y_test, \"(Tuned)\")\n"
      ],
      "metadata": {
        "id": "MN-nP9ywUPzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "colors = ['blue', 'green', 'purple']\n",
        "color_index = 0\n",
        "\n",
        "def plot_actual_vs_predicted_tuned(models_dict, X_test, y_test, title_suffix=\"\"):\n",
        "    global color_index  # Declare color_index as global\n",
        "    plt.figure(figsize=(10, 4 * len(models_dict))) # Adjust figure size based on number of models\n",
        "    for i, (name, model) in enumerate(models_dict.items()):\n",
        "        y_pred = model.predict(X_test)\n",
        "        current_color = colors[color_index % len(colors)]\n",
        "        color_index += 1\n",
        "        plt.subplot(len(models_dict), 1, i + 1) # Create subplots vertically\n",
        "        sns.scatterplot(x=y_test, y=y_pred, alpha=0.5, color = current_color)\n",
        "        # Plot a diagonal line for reference\n",
        "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "        plt.xlabel(\"Actual\")\n",
        "        plt.ylabel(\"Predicted\")\n",
        "        plt.title(f\"{name} {title_suffix}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usage with your tuned models (assuming you ran the RandomizedSearchCV code and have best_models_random)\n",
        "plot_actual_vs_predicted_tuned(best_models, X_test, y_test, \"(Tuned)\")"
      ],
      "metadata": {
        "id": "M0vkw0E8XGw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recidual Plot representation\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def plot_residuals(models_dict, X_test, y_test, title_suffix=\"\"):\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    for i, (name, model) in enumerate(models_dict.items()):\n",
        "        y_pred = model.predict(X_test)\n",
        "        residuals = y_test - y_pred\n",
        "        plt.subplot(1, len(models_dict), i + 1)\n",
        "        sns.scatterplot(x=y_pred, y=residuals, alpha=0.5)\n",
        "        plt.axhline(0, color='r', linestyle='--') # Add a horizontal line at zero\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Residuals\")\n",
        "        plt.title(f'{name} {title_suffix}: Residual Plot')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usage\n",
        "plot_residuals(models, X_test, y_test, \"(Default)\")\n",
        "plot_residuals(best_models, X_test, y_test, \"(Tuned)\")"
      ],
      "metadata": {
        "id": "Yn7cThgwyBDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLNgZK-r6QT9"
      },
      "outputs": [],
      "source": [
        "# Assuming 'season' is a valid column in your X_test DataFrame\n",
        "group_col = 'season'\n",
        "\n",
        "# Get predictions from the tuned models\n",
        "y_pred_xgb_tuned = best_models[\"XGBoost\"].predict(X_test)\n",
        "y_pred_rf_tuned = best_models[\"Random Forest\"].predict(X_test)\n",
        "y_pred_lgbm_tuned = best_models[\"LGBM\"].predict(X_test)\n",
        "\n",
        "# Dictionary of tuned model predictions\n",
        "tuned_predictions = {\n",
        "    \"XGBoost (Tuned)\": y_pred_xgb_tuned,\n",
        "    \"Random Forest (Tuned)\": y_pred_rf_tuned,\n",
        "    \"LGBM (Tuned)\": y_pred_lgbm_tuned\n",
        "}\n",
        "\n",
        "# Calculate grouped errors for tuned models\n",
        "grouped_errors_tuned = {\n",
        "    name: np.abs(y_test - pred).groupby(X_test[group_col]).mean()\n",
        "    for name, pred in tuned_predictions.items()\n",
        "}\n",
        "\n",
        "# Create DataFrame and plot heatmap for tuned models\n",
        "df_grouped_tuned = pd.DataFrame(grouped_errors_tuned)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df_grouped_tuned, annot=True, fmt=\".1f\", cmap=\"coolwarm\")\n",
        "plt.title(f\"Mean Absolute Error by {group_col} (Tuned Models)\")\n",
        "plt.ylabel(group_col)\n",
        "plt.xlabel(\"Model\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GBCOdFqTP3J"
      },
      "outputs": [],
      "source": [
        "# Sort by actual values for smooth lines\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sorted_idx = np.argsort(y_test[:100])\n",
        "\n",
        "# Get predictions from tuned models\n",
        "y_pred_xgb_tuned = best_models[\"XGBoost\"].predict(X_test[:100])\n",
        "y_pred_rf_tuned = best_models[\"Random Forest\"].predict(X_test[:100])\n",
        "y_pred_lgbm_tuned = best_models[\"LGBM\"].predict(X_test[:100])\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test.values[sorted_idx], label='Actual', color='black', linewidth=2)\n",
        "plt.plot(y_pred_xgb_tuned[sorted_idx], label='XGBoost (Tuned)', linestyle='--', color='red')\n",
        "plt.plot(y_pred_rf_tuned[sorted_idx], label='Random Forest (Tuned)', linestyle='--', color='green')\n",
        "plt.plot(y_pred_lgbm_tuned[sorted_idx], label='LGBM (Tuned)', linestyle='--', color='orange')\n",
        "plt.title('Actual vs Predicted (Sorted by Actual - Tuned Models)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('cnt')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTkWdwESgHi0"
      },
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyRegressor\n",
        "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
        "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
        "print(models)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ikyUJIDORJl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}